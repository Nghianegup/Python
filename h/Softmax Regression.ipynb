{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax (Z):\n",
    "    e_Z = np.exp(Z)\n",
    "    A = e_Z/ e_Z.sum(axis = 0)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### softmax function ổn định hơn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_stable(Z):\n",
    "    e_Z = np.exp(Z - np.max(Z, axis = 0 , keepdims = True))\n",
    "    A = e_Z / e_Z.sum(axis = 0)\n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2 \n",
    "d = 2 \n",
    "C = 3\n",
    "X = np.random.randn(d, N)\n",
    "y = np.random.randint(0, 3, (N,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_labels(y, C = C):\n",
    "    Y = sparse.coo_matrix((np.ones_like(y), \n",
    "        (y, np.arange(len(y)))), shape = (C, len(y))).toarray()\n",
    "    return Y \n",
    "\n",
    "Y = convert_labels(y, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9074845.956226652\n"
     ]
    }
   ],
   "source": [
    "def cost (X,Y,W):\n",
    "    A = softmax(W.T.dot(X))\n",
    "    return -np.sum(Y*np.log(A))\n",
    "W_init = np.random.randn(d,C)\n",
    "\n",
    "def grad (X,Y,W):\n",
    "    A = softmax((W.T.dot(X)))\n",
    "    E = A - Y\n",
    "    return X.dot(E.T)\n",
    "\n",
    "def numerical_grad(X, Y, W, cost):\n",
    "    eps = 1e-6\n",
    "    g = np.zeros_like(W)\n",
    "    for i in range (W.shape[0]):\n",
    "        for j in range(W.shape[1]):\n",
    "            W_p = W.copy()\n",
    "            W_n = W.copy()\n",
    "            W_p[i,j] += eps\n",
    "            W_n[i,j] -= eps\n",
    "            g[i,j] = cost(X,Y,W_p) - cost(X,Y,W_n)/(2*eps)\n",
    "    return g\n",
    "g1 = grad(X, Y, W_init)\n",
    "g2 = numerical_grad(X, Y, W_init, cost)\n",
    "\n",
    "print(np.linalg.norm(g1-g2))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_regression (X,Y,W_init,eta,tol = 1e-4,max_count = 10000):\n",
    "    W = [W_init]\n",
    "    C = W_init.shape[1]\n",
    "    Y = convert_labels(y,C)\n",
    "    it = 0 \n",
    "    N = X.shape[1]\n",
    "    d = X.shape[0]\n",
    "    count = 0 \n",
    "    check_w_after = 20 \n",
    "    while count < max_count:\n",
    "        mix_id = np.random.permutation(N)\n",
    "        for i in mix_id:\n",
    "            xi = X[:,i].reshape(d,1)\n",
    "            yi = Y[:,i].reshape(C,1)\n",
    "            ai = softmax(np.dot(W[-1].T,xi))\n",
    "            W_new = W[-1] + eta*xi.dot((yi - ai).T)\n",
    "            count += 1\n",
    "            \n",
    "            if count%check_w_after == 0:\n",
    "                if np.linalg.norm(W_new - W[-check_w_after]) < tol:\n",
    "                    return W\n",
    "            W.append(W_new)\n",
    "    return W\n",
    "eta = 0.05\n",
    "d = X.shape[0]\n",
    "W_init = np.random.randn(d,C)\n",
    "W = softmax_regression(X,Y,W_init,eta)\n",
    "            \n",
    "            \n",
    "                         \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(W,X):\n",
    "    A = softmax_stable(W.T.dot(X))\n",
    "    return np.argmax(A,axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [[2, 2], [8, 3], [3, 6]]\n",
    "cov = [[1, 0], [0, 1]]\n",
    "N = 500\n",
    "X0 = np.random.multivariate_normal(means[0], cov, N)\n",
    "X1 = np.random.multivariate_normal(means[1], cov, N)\n",
    "X2 = np.random.multivariate_normal(means[2], cov, N)\n",
    "\n",
    "# each column is a datapoint\n",
    "X = np.concatenate((X0, X1, X2), axis = 0).T \n",
    "# extended data\n",
    "X = np.concatenate((np.ones((1, 3*N)), X), axis = 0)\n",
    "C = 3\n",
    "\n",
    "original_label = np.asarray([0]*N + [1]*N + [2]*N).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-b8bc61bbf4d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mW_init\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoftmax_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moriginal_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "W_init = np.random.randn(X.shape[0], C)\n",
    "W = softmax_regression(X, original_label, W_init, eta)\n",
    "print(W[-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
